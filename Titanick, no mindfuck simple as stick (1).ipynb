{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport time\nimport math\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport scipy as sci\nimport plotly.offline as py\nimport plotly.graph_objs as go\npy.init_notebook_mode(connected=True)\nfrom matplotlib import pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#import data\ntest = pd.read_csv('../input/test.csv')\ntrain = pd.read_csv('../input/train.csv')\ncombine = [train,test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#func for observing data from https://www.kaggle.com/nholloway/catboost-v-xgboost-v-lightgbm\ndef meet_ur_data(df):\n    df = df\n    description = pd.DataFrame(index=['observations(rows)', 'percent missing', 'dtype', 'range'])\n    numerical = []\n    categorical = []\n    for col in df.columns:\n        obs = df[col].size\n        p_nan = round(df[col].isna().sum()/obs, 2)\n        num_nan = f'{p_nan}% ({df[col].isna().sum()}/{obs})'\n        dtype = 'categorical' if df[col].dtype == object else 'numerical'\n        numerical.append(col) if dtype == 'numerical' else categorical.append(col)\n        rng = f'{len(df[col].unique())} labels' if dtype == 'categorical' else f'{df[col].min()}-{df[col].max()}'\n        description[col] = [obs, num_nan, dtype, rng]\n\n    pd.set_option('display.max_columns', 100)\n    display(description)\n    display(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meet_ur_data(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sex, and Embarked transform to numerical sex=(male = 1, female = 0), Embarked = (S=0, C=1, Q=2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map({'female': 0,'male': 1}).astype(int)\nfreq_port = train.Embarked.dropna().mode()[0]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meet_ur_data(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Survived', 'Pclass', 'Sex', 'SibSp', 'Fare', 'Embarked','Parch']\npairplot = sns.pairplot(train[features], diag_kind='kde', hue='Survived')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Heatmap(\n    z = np.absolute(train[features].astype(float).corr().values),\n    x = train[features].columns.values,\n    y = train[features].columns.values,\n    colorscale = 'Portland', \n    reversescale = False, \n    opacity = 1.0)\n        \ndata = [trace1]\nlayout = go.Layout(\n    title = 'Correlation map (Numerical Features)',\n    xaxis = dict(ticks = '', nticks = 36),\n    yaxis = dict(ticks = ''),\n    width = 700, height = 700\n)\n\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['Ticket','Cabin','PassengerId','Name'],axis = 1)\ntest = test.drop(['Ticket','Cabin','Name'],axis = 1)\ncombine = [test,train]\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meet_ur_data(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling Age\nguess_ages = np.zeros((2,3))\nguess_ages\nfor dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meet_ur_data(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_2 = ['Survived', 'Pclass', 'Sex', 'SibSp', 'Fare', 'Embarked','Parch', 'Age']\ntrace1 = go.Heatmap(\n    z = np.absolute(train[features_2].astype(float).corr().values),\n    x = train[features_2].columns.values,\n    y = train[features_2].columns.values,\n    colorscale = 'Portland', \n    reversescale = False, \n    opacity = 1.0)\n        \ndata = [trace1]\nlayout = go.Layout(\n    title = 'Correlation map (Numerical Features)',\n    xaxis = dict(ticks = '', nticks = 36),\n    yaxis = dict(ticks = ''),\n    width = 700, height = 700\n)\n\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop(\"Survived\", axis=1)\nY_train = train[\"Survived\"]\nX_test  = test.drop(\"PassengerId\", axis=1).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom hyperopt import hp, tpe, Trials, STATUS_OK\nfrom hyperopt import fmin\n\ny_df = Y_train.copy()\nx_df = X_train.copy()\ntrain_x, test_x, train_y, test_y = train_test_split(x_df, y_df, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def org_results(trials, hyperparams, model_name):\n    fit_idx = -1\n    for idx, fit  in enumerate(trials):\n        hyp = fit['misc']['vals']\n        xgb_hyp = {key:[val] for key, val in hyperparams.items()}\n        if hyp == xgb_hyp:\n            fit_idx = idx\n            break\n            \n    train_time = str(trials[-1]['refresh_time'] - trials[0]['book_time'])\n    acc = round(trials[fit_idx]['result']['accuracy'], 3)\n    train_auc = round(trials[fit_idx]['result']['train auc'], 3)\n    test_auc = round(trials[fit_idx]['result']['test auc'], 3)\n\n    results = {\n        'model': model_name,\n        'parameter search time': train_time,\n        'accuracy': acc,\n        'test auc score': test_auc,\n        'training auc score': train_auc,\n        'parameters': hyperparams\n    }\n    return results","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgb_objective(space, early_stopping_rounds=50):\n    \n    model = XGBClassifier(\n        learning_rate = space['learning_rate'], \n        n_estimators = int(space['n_estimators']), \n        max_depth = int(space['max_depth']), \n        min_child_weight = space['m_child_weight'], \n        gamma = space['gamma'], \n        subsample = space['subsample'], \n        colsample_bytree = space['colsample_bytree'],\n        objective = 'binary:logistic'\n    )\n\n    model.fit(train_x, train_y, \n              eval_set = [(train_x, train_y), (test_x, test_y)],\n              eval_metric = 'auc',\n              early_stopping_rounds = early_stopping_rounds,\n              verbose = False)\n     \n    predictions = model.predict(test_x)\n    test_preds = model.predict_proba(test_x)[:,1]\n    train_preds = model.predict_proba(train_x)[:,1]\n    \n    xgb_booster = model.get_booster()\n    train_auc = roc_auc_score(train_y, train_preds)\n    test_auc = roc_auc_score(test_y, test_preds)\n    accuracy = accuracy_score(test_y, predictions) \n\n    return {'status': STATUS_OK, 'loss': 1-test_auc, 'accuracy': accuracy,\n            'test auc': test_auc, 'train auc': train_auc\n           }\nspace = {\n    'n_estimators': hp.quniform('n_estimators', 50, 1000, 25),\n    'max_depth': hp.quniform('max_depth', 1, 12, 1),\n    'm_child_weight': hp.quniform('m_child_weight', 1, 6, 1),\n    'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n    'learning_rate': hp.loguniform('learning_rate', np.log(.001), np.log(.3)),\n    'colsample_bytree': hp.quniform('colsample_bytree', .5, 1, .1)\n}\ntrials = Trials()\nxgb_hyperparams = fmin(fn = xgb_objective, \n                 max_evals = 1000, \n                 trials = trials,\n                 algo = tpe.suggest,\n                 space = space\n                )","execution_count":54,"outputs":[{"output_type":"stream","text":"100%|██████████| 1000/1000 [05:54<00:00,  2.04it/s, best loss: 0.06913931248384597]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_results = org_results(trials.trials, xgb_hyperparams, 'XGBoost')\ndisplay(xgb_results)","execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":"{'model': 'XGBoost',\n 'parameter search time': '0:00:20.879000',\n 'accuracy': 0.86,\n 'test auc score': 0.918,\n 'training auc score': 0.98,\n 'parameters': {'colsample_bytree': 0.9,\n  'gamma': 0.55,\n  'learning_rate': 0.1885950802549632,\n  'm_child_weight': 4,\n  'max_depth': 11,\n  'n_estimators': 300,\n  'subsample': 0.75}}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = xgb_hyperparams\nparams.update({ 'm_child_weight': 4,\n              'n_estimators': 300,\n               'max_depth': 11,\n              })\n\nNEO = XGBClassifier(**params)\n\nNEO.fit(X_train, Y_train, \n        verbose = False)\n    \nY_pred = NEO.predict(X_test)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#save\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}